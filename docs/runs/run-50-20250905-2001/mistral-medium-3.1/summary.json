{
  "overall_reward": 0.7833333333333333,
  "label_counts": {
    "very_low": 0,
    "low": 9,
    "medium": 14,
    "high": 27
  },
  "metrics_mean": {
    "composite_score": 0.7833333333333333,
    "C1_title_present": 1.0,
    "C2_quatrain_shape": 0.84,
    "C3_ballad_meter_echo": 0.36,
    "C4_ballad_rhyme": 0.74,
    "C5_ring_composition": 0.5,
    "C6_warning_admonition": 1.0,
    "C7_preparation_armament": 0.96,
    "C8_encounter_confrontation": 0.9,
    "C9_slaying_decisive_action": 0.68,
    "C10_return_celebration": 0.68,
    "C11_coinage_count": 0.44,
    "C12_coinage_spread": 0.54,
    "C13_creature_naming": 0.9,
    "C14_onomatopoeia": 0.62,
    "C15_alliteration_consonance": 0.74,
    "C16_arc_order": 0.76,
    "C17_no_verbatim_lines": 0.98,
    "C18_canonical_budget": 0.96,
    "C19_syllable_tightness": 0.74,
    "C20_rhyme_variety": 0.86,
    "C21_lexical_repetition_guard": 1.0,
    "C22_coinage_variety": 0.74,
    "C23_topic_adherence": 0.98,
    "C24_subtext": 0.88,
    "label_high": 0.54,
    "label_medium": 0.28,
    "label_low": 0.18,
    "label_very_low": 0.0
  },
  "total_score": 3917,
  "spec": "mistral-medium-3.1",
  "provider": "openrouter",
  "model": "mistralai/mistral-medium-3.1",
  "num_samples": 50
}