[
  {
    "spec": "gemini-2.5-flash",
    "provider": "openrouter",
    "model": "google/gemini-2.5-flash",
    "summary": {
      "overall_reward": 0.6516666666666667,
      "label_counts": {
        "very_low": 11,
        "low": 3,
        "medium": 14,
        "high": 22
      },
      "metrics_mean": {
        "composite_score": 0.6516666666666667,
        "C1_title_present": 0.96,
        "C2_quatrain_shape": 0.64,
        "C3_ballad_meter_echo": 0.38,
        "C4_ballad_rhyme": 0.64,
        "C5_ring_composition": 0.66,
        "C6_warning_admonition": 0.8,
        "C7_preparation_armament": 0.62,
        "C8_encounter_confrontation": 0.74,
        "C9_slaying_decisive_action": 0.64,
        "C10_return_celebration": 0.62,
        "C11_coinage_count": 0.5,
        "C12_coinage_spread": 0.56,
        "C13_creature_naming": 0.76,
        "C14_onomatopoeia": 0.42,
        "C15_alliteration_consonance": 0.64,
        "C16_arc_order": 0.64,
        "C17_no_verbatim_lines": 0.68,
        "C18_canonical_budget": 0.66,
        "C19_syllable_tightness": 0.6,
        "C20_rhyme_variety": 0.66,
        "C21_lexical_repetition_guard": 0.86,
        "C22_coinage_variety": 0.58,
        "C23_topic_adherence": 0.78,
        "C24_subtext": 0.6,
        "label_high": 0.44,
        "label_medium": 0.28,
        "label_low": 0.06,
        "label_very_low": 0.22
      },
      "total_score": 3258
    },
    "path": "gemini-2.5-flash/"
  },
  {
    "spec": "gemini-2.5-flash-lite",
    "provider": "openrouter",
    "model": "google/gemini-2.5-flash-lite",
    "summary": {
      "overall_reward": 0.7633333333333333,
      "label_counts": {
        "very_low": 2,
        "low": 2,
        "medium": 26,
        "high": 20
      },
      "metrics_mean": {
        "composite_score": 0.7633333333333333,
        "C1_title_present": 0.98,
        "C2_quatrain_shape": 0.86,
        "C3_ballad_meter_echo": 0.58,
        "C4_ballad_rhyme": 0.84,
        "C5_ring_composition": 0.94,
        "C6_warning_admonition": 0.94,
        "C7_preparation_armament": 0.94,
        "C8_encounter_confrontation": 0.94,
        "C9_slaying_decisive_action": 0.9,
        "C10_return_celebration": 0.88,
        "C11_coinage_count": 0.26,
        "C12_coinage_spread": 0.5,
        "C13_creature_naming": 0.82,
        "C14_onomatopoeia": 0.44,
        "C15_alliteration_consonance": 0.7,
        "C16_arc_order": 0.84,
        "C17_no_verbatim_lines": 0.6,
        "C18_canonical_budget": 0.56,
        "C19_syllable_tightness": 0.86,
        "C20_rhyme_variety": 0.84,
        "C21_lexical_repetition_guard": 0.92,
        "C22_coinage_variety": 0.48,
        "C23_topic_adherence": 0.96,
        "C24_subtext": 0.74,
        "label_high": 0.4,
        "label_medium": 0.52,
        "label_low": 0.04,
        "label_very_low": 0.04
      },
      "total_score": 3817
    },
    "path": "gemini-2.5-flash-lite/"
  },
  {
    "spec": "claude-3.5-haiku",
    "provider": "openrouter",
    "model": "anthropic/claude-3.5-haiku",
    "summary": {
      "overall_reward": 0.6,
      "label_counts": {
        "very_low": 8,
        "low": 17,
        "medium": 9,
        "high": 16
      },
      "metrics_mean": {
        "composite_score": 0.6,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.54,
        "C3_ballad_meter_echo": 0.36,
        "C4_ballad_rhyme": 0.72,
        "C5_ring_composition": 0.28,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.5,
        "C8_encounter_confrontation": 0.64,
        "C9_slaying_decisive_action": 0.56,
        "C10_return_celebration": 0.62,
        "C11_coinage_count": 0.12,
        "C12_coinage_spread": 0.36,
        "C13_creature_naming": 0.5,
        "C14_onomatopoeia": 0.12,
        "C15_alliteration_consonance": 0.4,
        "C16_arc_order": 0.46,
        "C17_no_verbatim_lines": 0.96,
        "C18_canonical_budget": 0.94,
        "C19_syllable_tightness": 0.64,
        "C20_rhyme_variety": 0.86,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.38,
        "C23_topic_adherence": 0.78,
        "C24_subtext": 0.66,
        "label_high": 0.32,
        "label_medium": 0.18,
        "label_low": 0.34,
        "label_very_low": 0.16
      },
      "total_score": 3000
    },
    "path": "claude-3.5-haiku/"
  },
  {
    "spec": "claude-3.7-sonnet",
    "provider": "openrouter",
    "model": "anthropic/claude-3.7-sonnet",
    "summary": {
      "overall_reward": 0.9583333333333333,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 1,
        "high": 49
      },
      "metrics_mean": {
        "composite_score": 0.9583333333333337,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 0.9,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 0.98,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.92,
        "C10_return_celebration": 0.96,
        "C11_coinage_count": 0.9,
        "C12_coinage_spread": 0.96,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.62,
        "C15_alliteration_consonance": 0.98,
        "C16_arc_order": 0.94,
        "C17_no_verbatim_lines": 0.9,
        "C18_canonical_budget": 0.94,
        "C19_syllable_tightness": 1.0,
        "C20_rhyme_variety": 1.0,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 1.0,
        "C23_topic_adherence": 1.0,
        "C24_subtext": 1.0,
        "label_high": 0.98,
        "label_medium": 0.02,
        "label_low": 0.0,
        "label_very_low": 0.0
      },
      "total_score": 4792
    },
    "path": "claude-3.7-sonnet/"
  },
  {
    "spec": "claude-sonnet-4",
    "provider": "openrouter",
    "model": "anthropic/claude-sonnet-4",
    "summary": {
      "overall_reward": 0.89,
      "label_counts": {
        "very_low": 0,
        "low": 1,
        "medium": 10,
        "high": 39
      },
      "metrics_mean": {
        "composite_score": 0.89,
        "C1_title_present": 0.98,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 0.9,
        "C4_ballad_rhyme": 0.96,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 0.98,
        "C7_preparation_armament": 0.98,
        "C8_encounter_confrontation": 0.98,
        "C9_slaying_decisive_action": 0.94,
        "C10_return_celebration": 0.98,
        "C11_coinage_count": 0.5,
        "C12_coinage_spread": 0.66,
        "C13_creature_naming": 0.96,
        "C14_onomatopoeia": 0.74,
        "C15_alliteration_consonance": 0.94,
        "C16_arc_order": 0.94,
        "C17_no_verbatim_lines": 0.68,
        "C18_canonical_budget": 0.66,
        "C19_syllable_tightness": 1.0,
        "C20_rhyme_variety": 0.98,
        "C21_lexical_repetition_guard": 0.96,
        "C22_coinage_variety": 0.74,
        "C23_topic_adherence": 0.98,
        "C24_subtext": 0.92,
        "label_high": 0.78,
        "label_medium": 0.2,
        "label_low": 0.02,
        "label_very_low": 0.0
      },
      "total_score": 4450
    },
    "path": "claude-sonnet-4/"
  },
  {
    "spec": "deepseek-chat-v3.1",
    "provider": "openrouter",
    "model": "deepseek/deepseek-chat-v3.1",
    "summary": {
      "overall_reward": 0.9516666666666667,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 2,
        "high": 48
      },
      "metrics_mean": {
        "composite_score": 0.9516666666666667,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.96,
        "C3_ballad_meter_echo": 0.76,
        "C4_ballad_rhyme": 0.96,
        "C5_ring_composition": 0.96,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 1.0,
        "C10_return_celebration": 0.98,
        "C11_coinage_count": 0.88,
        "C12_coinage_spread": 0.92,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.56,
        "C15_alliteration_consonance": 0.96,
        "C16_arc_order": 1.0,
        "C17_no_verbatim_lines": 0.98,
        "C18_canonical_budget": 0.96,
        "C19_syllable_tightness": 0.98,
        "C20_rhyme_variety": 1.0,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.98,
        "C23_topic_adherence": 1.0,
        "C24_subtext": 1.0,
        "label_high": 0.96,
        "label_medium": 0.04,
        "label_low": 0.0,
        "label_very_low": 0.0
      },
      "total_score": 4758
    },
    "path": "deepseek-chat-v3.1/"
  },
  {
    "spec": "claude-opus-4.1",
    "provider": "openrouter",
    "model": "anthropic/claude-opus-4.1",
    "summary": {
      "overall_reward": 0.8916666666666667,
      "label_counts": {
        "very_low": 4,
        "low": 0,
        "medium": 3,
        "high": 43
      },
      "metrics_mean": {
        "composite_score": 0.8916666666666666,
        "C1_title_present": 0.98,
        "C2_quatrain_shape": 0.9,
        "C3_ballad_meter_echo": 0.84,
        "C4_ballad_rhyme": 0.9,
        "C5_ring_composition": 0.92,
        "C6_warning_admonition": 0.92,
        "C7_preparation_armament": 0.92,
        "C8_encounter_confrontation": 0.92,
        "C9_slaying_decisive_action": 0.92,
        "C10_return_celebration": 0.92,
        "C11_coinage_count": 0.76,
        "C12_coinage_spread": 0.8,
        "C13_creature_naming": 0.9,
        "C14_onomatopoeia": 0.68,
        "C15_alliteration_consonance": 0.92,
        "C16_arc_order": 0.92,
        "C17_no_verbatim_lines": 0.98,
        "C18_canonical_budget": 0.84,
        "C19_syllable_tightness": 0.9,
        "C20_rhyme_variety": 0.92,
        "C21_lexical_repetition_guard": 0.94,
        "C22_coinage_variety": 0.88,
        "C23_topic_adherence": 0.92,
        "C24_subtext": 0.9,
        "label_high": 0.86,
        "label_medium": 0.06,
        "label_low": 0.0,
        "label_very_low": 0.08
      },
      "total_score": 4458
    },
    "path": "claude-opus-4.1/"
  },
  {
    "spec": "gpt-4o",
    "provider": "openrouter",
    "model": "openai/gpt-4o",
    "summary": {
      "overall_reward": 0.91,
      "label_counts": {
        "very_low": 0,
        "low": 1,
        "medium": 6,
        "high": 43
      },
      "metrics_mean": {
        "composite_score": 0.9100000000000001,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.98,
        "C3_ballad_meter_echo": 0.58,
        "C4_ballad_rhyme": 0.9,
        "C5_ring_composition": 0.9,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 0.98,
        "C9_slaying_decisive_action": 0.9,
        "C10_return_celebration": 0.9,
        "C11_coinage_count": 0.8,
        "C12_coinage_spread": 0.88,
        "C13_creature_naming": 0.94,
        "C14_onomatopoeia": 0.46,
        "C15_alliteration_consonance": 0.92,
        "C16_arc_order": 0.9,
        "C17_no_verbatim_lines": 0.98,
        "C18_canonical_budget": 1.0,
        "C19_syllable_tightness": 0.96,
        "C20_rhyme_variety": 0.98,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.92,
        "C23_topic_adherence": 0.98,
        "C24_subtext": 0.98,
        "label_high": 0.86,
        "label_medium": 0.12,
        "label_low": 0.02,
        "label_very_low": 0.0
      },
      "total_score": 4550
    },
    "path": "gpt-4o/"
  },
  {
    "spec": "gpt-4.1",
    "provider": "openai",
    "model": "gpt-4.1",
    "summary": {
      "overall_reward": 0.9575,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 2,
        "high": 48
      },
      "metrics_mean": {
        "composite_score": 0.9575000000000002,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 0.68,
        "C4_ballad_rhyme": 0.9,
        "C5_ring_composition": 0.96,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.92,
        "C10_return_celebration": 0.86,
        "C11_coinage_count": 1.0,
        "C12_coinage_spread": 1.0,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.78,
        "C15_alliteration_consonance": 1.0,
        "C16_arc_order": 0.9,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 1.0,
        "C19_syllable_tightness": 1.0,
        "C20_rhyme_variety": 1.0,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 1.0,
        "C23_topic_adherence": 1.0,
        "C24_subtext": 0.98,
        "label_high": 0.96,
        "label_medium": 0.04,
        "label_low": 0.0,
        "label_very_low": 0.0
      },
      "total_score": 4788
    },
    "path": "gpt-4.1/"
  },
  {
    "spec": "gpt-oss-120b",
    "provider": "openrouter",
    "model": "openai/gpt-oss-120b",
    "summary": {
      "overall_reward": 0.6066666666666667,
      "label_counts": {
        "very_low": 1,
        "low": 20,
        "medium": 21,
        "high": 8
      },
      "metrics_mean": {
        "composite_score": 0.6066666666666665,
        "C1_title_present": 0.98,
        "C2_quatrain_shape": 0.2,
        "C3_ballad_meter_echo": 0.1,
        "C4_ballad_rhyme": 0.42,
        "C5_ring_composition": 0.06,
        "C6_warning_admonition": 0.9,
        "C7_preparation_armament": 0.42,
        "C8_encounter_confrontation": 0.42,
        "C9_slaying_decisive_action": 0.46,
        "C10_return_celebration": 0.16,
        "C11_coinage_count": 0.92,
        "C12_coinage_spread": 0.96,
        "C13_creature_naming": 0.78,
        "C14_onomatopoeia": 0.12,
        "C15_alliteration_consonance": 0.84,
        "C16_arc_order": 0.3,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 1.0,
        "C19_syllable_tightness": 0.38,
        "C20_rhyme_variety": 0.68,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.94,
        "C23_topic_adherence": 0.88,
        "C24_subtext": 0.64,
        "label_high": 0.16,
        "label_medium": 0.42,
        "label_low": 0.4,
        "label_very_low": 0.02
      },
      "total_score": 3033
    },
    "path": "gpt-oss-120b/"
  },
  {
    "spec": "grok-3",
    "provider": "openrouter",
    "model": "x-ai/grok-3",
    "summary": {
      "overall_reward": 0.9425,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 5,
        "high": 45
      },
      "metrics_mean": {
        "composite_score": 0.9425,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.94,
        "C3_ballad_meter_echo": 0.88,
        "C4_ballad_rhyme": 0.92,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 1.0,
        "C10_return_celebration": 0.98,
        "C11_coinage_count": 0.82,
        "C12_coinage_spread": 0.88,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.46,
        "C15_alliteration_consonance": 0.98,
        "C16_arc_order": 1.0,
        "C17_no_verbatim_lines": 0.98,
        "C18_canonical_budget": 0.88,
        "C19_syllable_tightness": 0.96,
        "C20_rhyme_variety": 1.0,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.94,
        "C23_topic_adherence": 1.0,
        "C24_subtext": 1.0,
        "label_high": 0.9,
        "label_medium": 0.1,
        "label_low": 0.0,
        "label_very_low": 0.0
      },
      "total_score": 4712
    },
    "path": "grok-3/"
  },
  {
    "spec": "grok-code-fast-1",
    "provider": "openrouter",
    "model": "x-ai/grok-code-fast-1",
    "summary": {
      "overall_reward": 0.8675,
      "label_counts": {
        "very_low": 0,
        "low": 2,
        "medium": 14,
        "high": 34
      },
      "metrics_mean": {
        "composite_score": 0.8674999999999997,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.84,
        "C3_ballad_meter_echo": 0.68,
        "C4_ballad_rhyme": 0.84,
        "C5_ring_composition": 0.86,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.96,
        "C8_encounter_confrontation": 0.96,
        "C9_slaying_decisive_action": 0.98,
        "C10_return_celebration": 0.98,
        "C11_coinage_count": 0.82,
        "C12_coinage_spread": 0.78,
        "C13_creature_naming": 0.94,
        "C14_onomatopoeia": 0.46,
        "C15_alliteration_consonance": 0.92,
        "C16_arc_order": 0.88,
        "C17_no_verbatim_lines": 0.7,
        "C18_canonical_budget": 0.74,
        "C19_syllable_tightness": 0.84,
        "C20_rhyme_variety": 0.9,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.92,
        "C23_topic_adherence": 1.0,
        "C24_subtext": 0.82,
        "label_high": 0.68,
        "label_medium": 0.28,
        "label_low": 0.04,
        "label_very_low": 0.0
      },
      "total_score": 4338
    },
    "path": "grok-code-fast-1/"
  },
  {
    "spec": "hermes-4-70b",
    "provider": "openrouter",
    "model": "nousresearch/hermes-4-70b",
    "summary": {
      "overall_reward": 0.5166666666666666,
      "label_counts": {
        "very_low": 13,
        "low": 12,
        "medium": 19,
        "high": 6
      },
      "metrics_mean": {
        "composite_score": 0.5166666666666666,
        "C1_title_present": 0.6,
        "C2_quatrain_shape": 0.36,
        "C3_ballad_meter_echo": 0.24,
        "C4_ballad_rhyme": 0.38,
        "C5_ring_composition": 0.48,
        "C6_warning_admonition": 0.82,
        "C7_preparation_armament": 0.6,
        "C8_encounter_confrontation": 0.6,
        "C9_slaying_decisive_action": 0.64,
        "C10_return_celebration": 0.62,
        "C11_coinage_count": 0.32,
        "C12_coinage_spread": 0.34,
        "C13_creature_naming": 0.62,
        "C14_onomatopoeia": 0.2,
        "C15_alliteration_consonance": 0.52,
        "C16_arc_order": 0.56,
        "C17_no_verbatim_lines": 0.6,
        "C18_canonical_budget": 0.6,
        "C19_syllable_tightness": 0.44,
        "C20_rhyme_variety": 0.44,
        "C21_lexical_repetition_guard": 0.84,
        "C22_coinage_variety": 0.42,
        "C23_topic_adherence": 0.8,
        "C24_subtext": 0.36,
        "label_high": 0.12,
        "label_medium": 0.38,
        "label_low": 0.24,
        "label_very_low": 0.26
      },
      "total_score": 2583
    },
    "path": "hermes-4-70b/"
  },
  {
    "spec": "ernie-4.5-300b-a47b",
    "provider": "openrouter",
    "model": "baidu/ernie-4.5-300b-a47b",
    "summary": {
      "overall_reward": 0.7483333333333333,
      "label_counts": {
        "very_low": 1,
        "low": 10,
        "medium": 15,
        "high": 24
      },
      "metrics_mean": {
        "composite_score": 0.7483333333333333,
        "C1_title_present": 0.98,
        "C2_quatrain_shape": 0.82,
        "C3_ballad_meter_echo": 0.24,
        "C4_ballad_rhyme": 0.56,
        "C5_ring_composition": 0.34,
        "C6_warning_admonition": 0.88,
        "C7_preparation_armament": 0.78,
        "C8_encounter_confrontation": 0.72,
        "C9_slaying_decisive_action": 0.7,
        "C10_return_celebration": 0.5,
        "C11_coinage_count": 0.9,
        "C12_coinage_spread": 0.92,
        "C13_creature_naming": 0.84,
        "C14_onomatopoeia": 0.42,
        "C15_alliteration_consonance": 0.84,
        "C16_arc_order": 0.62,
        "C17_no_verbatim_lines": 0.98,
        "C18_canonical_budget": 0.96,
        "C19_syllable_tightness": 0.52,
        "C20_rhyme_variety": 0.8,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.96,
        "C23_topic_adherence": 0.86,
        "C24_subtext": 0.82,
        "label_high": 0.48,
        "label_medium": 0.3,
        "label_low": 0.2,
        "label_very_low": 0.02
      },
      "total_score": 3742
    },
    "path": "ernie-4.5-300b-a47b/"
  },
  {
    "spec": "hermes-4-405b",
    "provider": "openrouter",
    "model": "nousresearch/hermes-4-405b",
    "summary": {
      "overall_reward": 0.7175,
      "label_counts": {
        "very_low": 5,
        "low": 8,
        "medium": 17,
        "high": 20
      },
      "metrics_mean": {
        "composite_score": 0.7175,
        "C1_title_present": 0.76,
        "C2_quatrain_shape": 0.6,
        "C3_ballad_meter_echo": 0.42,
        "C4_ballad_rhyme": 0.68,
        "C5_ring_composition": 0.62,
        "C6_warning_admonition": 0.92,
        "C7_preparation_armament": 0.92,
        "C8_encounter_confrontation": 0.84,
        "C9_slaying_decisive_action": 0.82,
        "C10_return_celebration": 0.8,
        "C11_coinage_count": 0.38,
        "C12_coinage_spread": 0.48,
        "C13_creature_naming": 0.8,
        "C14_onomatopoeia": 0.46,
        "C15_alliteration_consonance": 0.62,
        "C16_arc_order": 0.8,
        "C17_no_verbatim_lines": 0.86,
        "C18_canonical_budget": 0.88,
        "C19_syllable_tightness": 0.66,
        "C20_rhyme_variety": 0.72,
        "C21_lexical_repetition_guard": 0.96,
        "C22_coinage_variety": 0.54,
        "C23_topic_adherence": 0.92,
        "C24_subtext": 0.76,
        "label_high": 0.4,
        "label_medium": 0.34,
        "label_low": 0.16,
        "label_very_low": 0.1
      },
      "total_score": 3588
    },
    "path": "hermes-4-405b/"
  },
  {
    "spec": "gemini-2.5-pro",
    "provider": "openrouter",
    "model": "google/gemini-2.5-pro",
    "summary": {
      "overall_reward": 0.935,
      "label_counts": {
        "very_low": 0,
        "low": 2,
        "medium": 3,
        "high": 45
      },
      "metrics_mean": {
        "composite_score": 0.9350000000000002,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 0.8,
        "C4_ballad_rhyme": 0.92,
        "C5_ring_composition": 0.94,
        "C6_warning_admonition": 0.92,
        "C7_preparation_armament": 0.88,
        "C8_encounter_confrontation": 0.9,
        "C9_slaying_decisive_action": 0.88,
        "C10_return_celebration": 0.88,
        "C11_coinage_count": 1.0,
        "C12_coinage_spread": 0.98,
        "C13_creature_naming": 0.98,
        "C14_onomatopoeia": 0.7,
        "C15_alliteration_consonance": 0.96,
        "C16_arc_order": 0.88,
        "C17_no_verbatim_lines": 0.96,
        "C18_canonical_budget": 0.98,
        "C19_syllable_tightness": 0.96,
        "C20_rhyme_variety": 0.96,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 1.0,
        "C23_topic_adherence": 0.98,
        "C24_subtext": 0.98,
        "label_high": 0.9,
        "label_medium": 0.06,
        "label_low": 0.04,
        "label_very_low": 0.0
      },
      "total_score": 4675
    },
    "path": "gemini-2.5-pro/"
  },
  {
    "spec": "jamba-large-1.7",
    "provider": "openrouter",
    "model": "ai21/jamba-large-1.7",
    "summary": {
      "overall_reward": 0.54,
      "label_counts": {
        "very_low": 11,
        "low": 20,
        "medium": 8,
        "high": 11
      },
      "metrics_mean": {
        "composite_score": 0.5399999999999999,
        "C1_title_present": 0.92,
        "C2_quatrain_shape": 0.72,
        "C3_ballad_meter_echo": 0.14,
        "C4_ballad_rhyme": 0.5,
        "C5_ring_composition": 0.28,
        "C6_warning_admonition": 0.84,
        "C7_preparation_armament": 0.64,
        "C8_encounter_confrontation": 0.42,
        "C9_slaying_decisive_action": 0.42,
        "C10_return_celebration": 0.4,
        "C11_coinage_count": 0.28,
        "C12_coinage_spread": 0.36,
        "C13_creature_naming": 0.4,
        "C14_onomatopoeia": 0.22,
        "C15_alliteration_consonance": 0.46,
        "C16_arc_order": 0.38,
        "C17_no_verbatim_lines": 0.96,
        "C18_canonical_budget": 0.94,
        "C19_syllable_tightness": 0.32,
        "C20_rhyme_variety": 0.66,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.42,
        "C23_topic_adherence": 0.68,
        "C24_subtext": 0.6,
        "label_high": 0.22,
        "label_medium": 0.16,
        "label_low": 0.4,
        "label_very_low": 0.22
      },
      "total_score": 2700
    },
    "path": "jamba-large-1.7/"
  },
  {
    "spec": "grok-4",
    "provider": "openrouter",
    "model": "x-ai/grok-4",
    "summary": {
      "overall_reward": 0.9458333333333333,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 2,
        "high": 48
      },
      "metrics_mean": {
        "composite_score": 0.9458333333333334,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 0.98,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.98,
        "C10_return_celebration": 1.0,
        "C11_coinage_count": 0.74,
        "C12_coinage_spread": 0.86,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.64,
        "C15_alliteration_consonance": 0.96,
        "C16_arc_order": 1.0,
        "C17_no_verbatim_lines": 0.9,
        "C18_canonical_budget": 0.76,
        "C19_syllable_tightness": 1.0,
        "C20_rhyme_variety": 1.0,
        "C21_lexical_repetition_guard": 0.98,
        "C22_coinage_variety": 0.94,
        "C23_topic_adherence": 1.0,
        "C24_subtext": 0.96,
        "label_high": 0.96,
        "label_medium": 0.04,
        "label_low": 0.0,
        "label_very_low": 0.0
      },
      "total_score": 4729
    },
    "path": "grok-4/"
  },
  {
    "spec": "kimi-k2",
    "provider": "openrouter",
    "model": "moonshotai/kimi-k2",
    "summary": {
      "overall_reward": 0.88,
      "label_counts": {
        "very_low": 0,
        "low": 5,
        "medium": 7,
        "high": 38
      },
      "metrics_mean": {
        "composite_score": 0.88,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.7,
        "C3_ballad_meter_echo": 0.52,
        "C4_ballad_rhyme": 0.8,
        "C5_ring_composition": 0.7,
        "C6_warning_admonition": 0.98,
        "C7_preparation_armament": 0.94,
        "C8_encounter_confrontation": 0.92,
        "C9_slaying_decisive_action": 0.92,
        "C10_return_celebration": 0.86,
        "C11_coinage_count": 0.9,
        "C12_coinage_spread": 0.96,
        "C13_creature_naming": 0.94,
        "C14_onomatopoeia": 0.66,
        "C15_alliteration_consonance": 0.94,
        "C16_arc_order": 0.84,
        "C17_no_verbatim_lines": 0.98,
        "C18_canonical_budget": 0.96,
        "C19_syllable_tightness": 0.78,
        "C20_rhyme_variety": 0.9,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.98,
        "C23_topic_adherence": 0.96,
        "C24_subtext": 0.98,
        "label_high": 0.76,
        "label_medium": 0.14,
        "label_low": 0.1,
        "label_very_low": 0.0
      },
      "total_score": 4400
    },
    "path": "kimi-k2/"
  },
  {
    "spec": "kimi-k2-0905",
    "provider": "openrouter",
    "model": "moonshotai/kimi-k2-0905",
    "summary": {
      "overall_reward": 0.885,
      "label_counts": {
        "very_low": 0,
        "low": 4,
        "medium": 5,
        "high": 41
      },
      "metrics_mean": {
        "composite_score": 0.8849999999999999,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.86,
        "C3_ballad_meter_echo": 0.66,
        "C4_ballad_rhyme": 0.86,
        "C5_ring_composition": 0.84,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.94,
        "C8_encounter_confrontation": 0.9,
        "C9_slaying_decisive_action": 0.84,
        "C10_return_celebration": 0.82,
        "C11_coinage_count": 0.8,
        "C12_coinage_spread": 0.9,
        "C13_creature_naming": 0.92,
        "C14_onomatopoeia": 0.5,
        "C15_alliteration_consonance": 0.92,
        "C16_arc_order": 0.88,
        "C17_no_verbatim_lines": 0.96,
        "C18_canonical_budget": 0.9,
        "C19_syllable_tightness": 0.9,
        "C20_rhyme_variety": 0.94,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.94,
        "C23_topic_adherence": 0.98,
        "C24_subtext": 0.98,
        "label_high": 0.82,
        "label_medium": 0.1,
        "label_low": 0.08,
        "label_very_low": 0.0
      },
      "total_score": 4425
    },
    "path": "kimi-k2-0905/"
  },
  {
    "spec": "llama-3.3-70b-instruct",
    "provider": "openrouter",
    "model": "meta-llama/llama-3.3-70b-instruct",
    "summary": {
      "overall_reward": 0.3983333333333334,
      "label_counts": {
        "very_low": 13,
        "low": 29,
        "medium": 8,
        "high": 0
      },
      "metrics_mean": {
        "composite_score": 0.39833333333333343,
        "C1_title_present": 0.54,
        "C2_quatrain_shape": 0.88,
        "C3_ballad_meter_echo": 0.04,
        "C4_ballad_rhyme": 0.38,
        "C5_ring_composition": 0.04,
        "C6_warning_admonition": 0.7,
        "C7_preparation_armament": 0.48,
        "C8_encounter_confrontation": 0.14,
        "C9_slaying_decisive_action": 0.2,
        "C10_return_celebration": 0.16,
        "C11_coinage_count": 0.08,
        "C12_coinage_spread": 0.2,
        "C13_creature_naming": 0.2,
        "C14_onomatopoeia": 0.04,
        "C15_alliteration_consonance": 0.3,
        "C16_arc_order": 0.1,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 1.0,
        "C19_syllable_tightness": 0.26,
        "C20_rhyme_variety": 0.58,
        "C21_lexical_repetition_guard": 0.98,
        "C22_coinage_variety": 0.32,
        "C23_topic_adherence": 0.5,
        "C24_subtext": 0.44,
        "label_high": 0.0,
        "label_medium": 0.16,
        "label_low": 0.58,
        "label_very_low": 0.26
      },
      "total_score": 1992
    },
    "path": "llama-3.3-70b-instruct/"
  },
  {
    "spec": "deepseek-r1-0528",
    "provider": "openrouter",
    "model": "deepseek/deepseek-r1-0528",
    "summary": {
      "overall_reward": 0.97,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 1,
        "high": 49
      },
      "metrics_mean": {
        "composite_score": 0.9700000000000002,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.92,
        "C3_ballad_meter_echo": 0.86,
        "C4_ballad_rhyme": 0.94,
        "C5_ring_composition": 0.9,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.98,
        "C10_return_celebration": 0.92,
        "C11_coinage_count": 1.0,
        "C12_coinage_spread": 1.0,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.86,
        "C15_alliteration_consonance": 1.0,
        "C16_arc_order": 0.98,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 1.0,
        "C19_syllable_tightness": 0.94,
        "C20_rhyme_variety": 1.0,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 1.0,
        "C23_topic_adherence": 1.0,
        "C24_subtext": 0.98,
        "label_high": 0.98,
        "label_medium": 0.02,
        "label_low": 0.0,
        "label_very_low": 0.0
      },
      "total_score": 4850
    },
    "path": "deepseek-r1-0528/"
  },
  {
    "spec": "glm-4.5",
    "provider": "openrouter",
    "model": "z-ai/glm-4.5",
    "summary": {
      "overall_reward": 0.9041666666666667,
      "label_counts": {
        "very_low": 0,
        "low": 1,
        "medium": 10,
        "high": 39
      },
      "metrics_mean": {
        "composite_score": 0.9041666666666667,
        "C1_title_present": 0.98,
        "C2_quatrain_shape": 0.98,
        "C3_ballad_meter_echo": 0.96,
        "C4_ballad_rhyme": 0.98,
        "C5_ring_composition": 0.92,
        "C6_warning_admonition": 0.98,
        "C7_preparation_armament": 0.98,
        "C8_encounter_confrontation": 0.98,
        "C9_slaying_decisive_action": 0.98,
        "C10_return_celebration": 0.98,
        "C11_coinage_count": 0.66,
        "C12_coinage_spread": 0.78,
        "C13_creature_naming": 0.96,
        "C14_onomatopoeia": 0.7,
        "C15_alliteration_consonance": 0.96,
        "C16_arc_order": 0.98,
        "C17_no_verbatim_lines": 0.64,
        "C18_canonical_budget": 0.66,
        "C19_syllable_tightness": 0.98,
        "C20_rhyme_variety": 1.0,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.8,
        "C23_topic_adherence": 0.98,
        "C24_subtext": 0.88,
        "label_high": 0.78,
        "label_medium": 0.2,
        "label_low": 0.02,
        "label_very_low": 0.0
      },
      "total_score": 4521
    },
    "path": "glm-4.5/"
  },
  {
    "spec": "llama-3.1-405b-instruct",
    "provider": "openrouter",
    "model": "meta-llama/llama-3.1-405b-instruct",
    "summary": {
      "overall_reward": 0.5858333333333333,
      "label_counts": {
        "very_low": 7,
        "low": 13,
        "medium": 22,
        "high": 8
      },
      "metrics_mean": {
        "composite_score": 0.5858333333333333,
        "C1_title_present": 0.86,
        "C2_quatrain_shape": 0.64,
        "C3_ballad_meter_echo": 0.34,
        "C4_ballad_rhyme": 0.46,
        "C5_ring_composition": 0.48,
        "C6_warning_admonition": 0.88,
        "C7_preparation_armament": 0.8,
        "C8_encounter_confrontation": 0.66,
        "C9_slaying_decisive_action": 0.64,
        "C10_return_celebration": 0.56,
        "C11_coinage_count": 0.26,
        "C12_coinage_spread": 0.38,
        "C13_creature_naming": 0.62,
        "C14_onomatopoeia": 0.3,
        "C15_alliteration_consonance": 0.56,
        "C16_arc_order": 0.56,
        "C17_no_verbatim_lines": 0.68,
        "C18_canonical_budget": 0.6,
        "C19_syllable_tightness": 0.5,
        "C20_rhyme_variety": 0.42,
        "C21_lexical_repetition_guard": 0.94,
        "C22_coinage_variety": 0.46,
        "C23_topic_adherence": 0.86,
        "C24_subtext": 0.6,
        "label_high": 0.16,
        "label_medium": 0.44,
        "label_low": 0.26,
        "label_very_low": 0.14
      },
      "total_score": 2929
    },
    "path": "llama-3.1-405b-instruct/"
  },
  {
    "spec": "mistral-medium-3.1",
    "provider": "openrouter",
    "model": "mistralai/mistral-medium-3.1",
    "summary": {
      "overall_reward": 0.7833333333333333,
      "label_counts": {
        "very_low": 0,
        "low": 9,
        "medium": 14,
        "high": 27
      },
      "metrics_mean": {
        "composite_score": 0.7833333333333333,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.84,
        "C3_ballad_meter_echo": 0.36,
        "C4_ballad_rhyme": 0.74,
        "C5_ring_composition": 0.5,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.96,
        "C8_encounter_confrontation": 0.9,
        "C9_slaying_decisive_action": 0.68,
        "C10_return_celebration": 0.68,
        "C11_coinage_count": 0.44,
        "C12_coinage_spread": 0.54,
        "C13_creature_naming": 0.9,
        "C14_onomatopoeia": 0.62,
        "C15_alliteration_consonance": 0.74,
        "C16_arc_order": 0.76,
        "C17_no_verbatim_lines": 0.98,
        "C18_canonical_budget": 0.96,
        "C19_syllable_tightness": 0.74,
        "C20_rhyme_variety": 0.86,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.74,
        "C23_topic_adherence": 0.98,
        "C24_subtext": 0.88,
        "label_high": 0.54,
        "label_medium": 0.28,
        "label_low": 0.18,
        "label_very_low": 0.0
      },
      "total_score": 3917
    },
    "path": "mistral-medium-3.1/"
  },
  {
    "spec": "qwen3-30b-a3b-instruct-2507",
    "provider": "openrouter",
    "model": "qwen/qwen3-30b-a3b-instruct-2507",
    "summary": {
      "overall_reward": 0.6891666666666667,
      "label_counts": {
        "very_low": 1,
        "low": 10,
        "medium": 27,
        "high": 12
      },
      "metrics_mean": {
        "composite_score": 0.6891666666666668,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.52,
        "C3_ballad_meter_echo": 0.14,
        "C4_ballad_rhyme": 0.5,
        "C5_ring_composition": 0.18,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.72,
        "C8_encounter_confrontation": 0.72,
        "C9_slaying_decisive_action": 0.52,
        "C10_return_celebration": 0.28,
        "C11_coinage_count": 0.86,
        "C12_coinage_spread": 0.8,
        "C13_creature_naming": 0.82,
        "C14_onomatopoeia": 0.64,
        "C15_alliteration_consonance": 0.92,
        "C16_arc_order": 0.38,
        "C17_no_verbatim_lines": 0.9,
        "C18_canonical_budget": 0.94,
        "C19_syllable_tightness": 0.34,
        "C20_rhyme_variety": 0.68,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.92,
        "C23_topic_adherence": 0.94,
        "C24_subtext": 0.82,
        "label_high": 0.24,
        "label_medium": 0.54,
        "label_low": 0.2,
        "label_very_low": 0.02
      },
      "total_score": 3446
    },
    "path": "qwen3-30b-a3b-instruct-2507/"
  },
  {
    "spec": "qwen3-235b-a22b-2507",
    "provider": "openrouter",
    "model": "qwen/qwen3-235b-a22b-2507",
    "summary": {
      "overall_reward": 0.8525,
      "label_counts": {
        "very_low": 0,
        "low": 2,
        "medium": 14,
        "high": 34
      },
      "metrics_mean": {
        "composite_score": 0.8524999999999998,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.72,
        "C3_ballad_meter_echo": 0.44,
        "C4_ballad_rhyme": 0.72,
        "C5_ring_composition": 0.74,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.96,
        "C8_encounter_confrontation": 0.96,
        "C9_slaying_decisive_action": 0.86,
        "C10_return_celebration": 0.84,
        "C11_coinage_count": 0.8,
        "C12_coinage_spread": 0.86,
        "C13_creature_naming": 0.8,
        "C14_onomatopoeia": 0.52,
        "C15_alliteration_consonance": 0.9,
        "C16_arc_order": 0.88,
        "C17_no_verbatim_lines": 0.94,
        "C18_canonical_budget": 1.0,
        "C19_syllable_tightness": 0.8,
        "C20_rhyme_variety": 0.82,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.92,
        "C23_topic_adherence": 0.98,
        "C24_subtext": 1.0,
        "label_high": 0.68,
        "label_medium": 0.28,
        "label_low": 0.04,
        "label_very_low": 0.0
      },
      "total_score": 4262
    },
    "path": "qwen3-235b-a22b-2507/"
  },
  {
    "spec": "qwen3-max",
    "provider": "openrouter",
    "model": "qwen/qwen3-max",
    "summary": {
      "overall_reward": 0.9125,
      "label_counts": {
        "very_low": 0,
        "low": 1,
        "medium": 5,
        "high": 44
      },
      "metrics_mean": {
        "composite_score": 0.9125000000000001,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 0.72,
        "C4_ballad_rhyme": 0.92,
        "C5_ring_composition": 0.98,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 0.96,
        "C9_slaying_decisive_action": 0.92,
        "C10_return_celebration": 0.94,
        "C11_coinage_count": 0.62,
        "C12_coinage_spread": 0.76,
        "C13_creature_naming": 0.88,
        "C14_onomatopoeia": 0.6,
        "C15_alliteration_consonance": 0.92,
        "C16_arc_order": 0.96,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 1.0,
        "C19_syllable_tightness": 0.96,
        "C20_rhyme_variety": 0.98,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.8,
        "C23_topic_adherence": 0.98,
        "C24_subtext": 1.0,
        "label_high": 0.88,
        "label_medium": 0.1,
        "label_low": 0.02,
        "label_very_low": 0.0
      },
      "total_score": 4562
    },
    "path": "qwen3-max/"
  },
  {
    "spec": "o3",
    "provider": "openai",
    "model": "o3",
    "summary": {
      "overall_reward": 0.9858333333333333,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 0,
        "high": 50
      },
      "metrics_mean": {
        "composite_score": 0.9858333333333336,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 0.88,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 0.96,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 1.0,
        "C10_return_celebration": 0.96,
        "C11_coinage_count": 1.0,
        "C12_coinage_spread": 1.0,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.9,
        "C15_alliteration_consonance": 1.0,
        "C16_arc_order": 0.98,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 1.0,
        "C19_syllable_tightness": 0.98,
        "C20_rhyme_variety": 1.0,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 1.0,
        "C23_topic_adherence": 1.0,
        "C24_subtext": 1.0,
        "label_high": 1.0,
        "label_medium": 0.0,
        "label_low": 0.0,
        "label_very_low": 0.0
      },
      "total_score": 4929
    },
    "path": "o3/"
  },
  {
    "spec": "sonnet-3.5",
    "provider": "openrouter",
    "model": "anthropic/claude-3.5-sonnet",
    "summary": {
      "overall_reward": 0.9258333333333333,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 6,
        "high": 44
      },
      "metrics_mean": {
        "composite_score": 0.9258333333333336,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 0.74,
        "C4_ballad_rhyme": 0.96,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 0.98,
        "C7_preparation_armament": 0.96,
        "C8_encounter_confrontation": 0.98,
        "C9_slaying_decisive_action": 0.86,
        "C10_return_celebration": 0.94,
        "C11_coinage_count": 0.84,
        "C12_coinage_spread": 0.9,
        "C13_creature_naming": 0.92,
        "C14_onomatopoeia": 0.5,
        "C15_alliteration_consonance": 0.88,
        "C16_arc_order": 0.88,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 1.0,
        "C19_syllable_tightness": 1.0,
        "C20_rhyme_variety": 0.98,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 0.94,
        "C23_topic_adherence": 1.0,
        "C24_subtext": 0.96,
        "label_high": 0.88,
        "label_medium": 0.12,
        "label_low": 0.0,
        "label_very_low": 0.0
      },
      "total_score": 4629
    },
    "path": "sonnet-3.5/"
  },
  {
    "spec": "gpt-5",
    "provider": "openai",
    "model": "gpt-5",
    "summary": {
      "overall_reward": 0.91,
      "label_counts": {
        "very_low": 0,
        "low": 3,
        "medium": 4,
        "high": 43
      },
      "metrics_mean": {
        "composite_score": 0.9099999999999998,
        "C1_title_present": 0.96,
        "C2_quatrain_shape": 0.88,
        "C3_ballad_meter_echo": 0.64,
        "C4_ballad_rhyme": 0.9,
        "C5_ring_composition": 0.8,
        "C6_warning_admonition": 0.9,
        "C7_preparation_armament": 0.9,
        "C8_encounter_confrontation": 0.92,
        "C9_slaying_decisive_action": 0.86,
        "C10_return_celebration": 0.82,
        "C11_coinage_count": 0.98,
        "C12_coinage_spread": 0.98,
        "C13_creature_naming": 0.94,
        "C14_onomatopoeia": 0.86,
        "C15_alliteration_consonance": 0.98,
        "C16_arc_order": 0.88,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 1.0,
        "C19_syllable_tightness": 0.86,
        "C20_rhyme_variety": 0.92,
        "C21_lexical_repetition_guard": 0.96,
        "C22_coinage_variety": 1.0,
        "C23_topic_adherence": 0.92,
        "C24_subtext": 0.98,
        "label_high": 0.86,
        "label_medium": 0.08,
        "label_low": 0.06,
        "label_very_low": 0.0
      },
      "total_score": 4550
    },
    "path": "gpt-5/"
  },
  {
    "spec": "o4-mini",
    "provider": "openai",
    "model": "o4-mini",
    "summary": {
      "overall_reward": 0.7866666666666667,
      "label_counts": {
        "very_low": 0,
        "low": 5,
        "medium": 18,
        "high": 27
      },
      "metrics_mean": {
        "composite_score": 0.7866666666666666,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.62,
        "C3_ballad_meter_echo": 0.26,
        "C4_ballad_rhyme": 0.72,
        "C5_ring_composition": 0.18,
        "C6_warning_admonition": 0.94,
        "C7_preparation_armament": 0.9,
        "C8_encounter_confrontation": 0.78,
        "C9_slaying_decisive_action": 0.72,
        "C10_return_celebration": 0.68,
        "C11_coinage_count": 0.96,
        "C12_coinage_spread": 0.9,
        "C13_creature_naming": 0.86,
        "C14_onomatopoeia": 0.22,
        "C15_alliteration_consonance": 0.98,
        "C16_arc_order": 0.68,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 1.0,
        "C19_syllable_tightness": 0.76,
        "C20_rhyme_variety": 0.92,
        "C21_lexical_repetition_guard": 1.0,
        "C22_coinage_variety": 1.0,
        "C23_topic_adherence": 0.92,
        "C24_subtext": 0.88,
        "label_high": 0.54,
        "label_medium": 0.36,
        "label_low": 0.1,
        "label_very_low": 0.0
      },
      "total_score": 3933
    },
    "path": "o4-mini/"
  },
  {
    "spec": "kimi-dev-72b",
    "provider": "openrouter",
    "model": "moonshotai/kimi-dev-72b",
    "summary": {
      "overall_reward": 0.48166666666666663,
      "label_counts": {
        "very_low": 16,
        "low": 16,
        "medium": 11,
        "high": 7
      },
      "metrics_mean": {
        "composite_score": 0.48166666666666663,
        "C1_title_present": 0.82,
        "C2_quatrain_shape": 0.34,
        "C3_ballad_meter_echo": 0.1,
        "C4_ballad_rhyme": 0.36,
        "C5_ring_composition": 0.16,
        "C6_warning_admonition": 0.44,
        "C7_preparation_armament": 0.54,
        "C8_encounter_confrontation": 0.64,
        "C9_slaying_decisive_action": 0.64,
        "C10_return_celebration": 0.32,
        "C11_coinage_count": 0.3,
        "C12_coinage_spread": 0.4,
        "C13_creature_naming": 0.62,
        "C14_onomatopoeia": 0.1,
        "C15_alliteration_consonance": 0.26,
        "C16_arc_order": 0.3,
        "C17_no_verbatim_lines": 0.9,
        "C18_canonical_budget": 0.86,
        "C19_syllable_tightness": 0.44,
        "C20_rhyme_variety": 0.56,
        "C21_lexical_repetition_guard": 0.96,
        "C22_coinage_variety": 0.44,
        "C23_topic_adherence": 0.72,
        "C24_subtext": 0.34,
        "label_high": 0.14,
        "label_medium": 0.22,
        "label_low": 0.32,
        "label_very_low": 0.32
      },
      "total_score": 2408
    },
    "path": "kimi-dev-72b/"
  }
]