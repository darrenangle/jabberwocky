{
  "overall_reward": 0.6683333333333333,
  "label_counts": {
    "very_low": 5,
    "low": 8,
    "medium": 22,
    "high": 15
  },
  "metrics_mean": {
    "composite_score": 0.6683333333333333,
    "C1_title_present": 0.92,
    "C2_quatrain_shape": 0.4,
    "C3_ballad_meter_echo": 0.12,
    "C4_ballad_rhyme": 0.32,
    "C5_ring_composition": 0.28,
    "C6_warning_admonition": 0.82,
    "C7_preparation_armament": 0.8,
    "C8_encounter_confrontation": 0.8,
    "C9_slaying_decisive_action": 0.7,
    "C10_return_celebration": 0.54,
    "C11_coinage_count": 0.8,
    "C12_coinage_spread": 0.72,
    "C13_creature_naming": 0.9,
    "C14_onomatopoeia": 0.18,
    "C15_alliteration_consonance": 0.76,
    "C16_arc_order": 0.64,
    "C17_no_verbatim_lines": 0.96,
    "C18_canonical_budget": 0.92,
    "C19_syllable_tightness": 0.4,
    "C20_rhyme_variety": 0.64,
    "C21_lexical_repetition_guard": 0.96,
    "C22_coinage_variety": 0.84,
    "C23_topic_adherence": 0.88,
    "C24_subtext": 0.74,
    "label_high": 0.3,
    "label_medium": 0.44,
    "label_low": 0.16,
    "label_very_low": 0.1
  },
  "total_score": 3342,
  "spec": "hermes-4-70b",
  "provider": "openrouter",
  "model": "nousresearch/hermes-4-70b",
  "num_samples": 50
}