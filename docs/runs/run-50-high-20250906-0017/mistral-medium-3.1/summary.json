{
  "overall_reward": 0.8733333333333333,
  "label_counts": {
    "very_low": 0,
    "low": 0,
    "medium": 11,
    "high": 39
  },
  "metrics_mean": {
    "composite_score": 0.873333333333333,
    "C1_title_present": 1.0,
    "C2_quatrain_shape": 0.98,
    "C3_ballad_meter_echo": 0.44,
    "C4_ballad_rhyme": 0.78,
    "C5_ring_composition": 0.46,
    "C6_warning_admonition": 1.0,
    "C7_preparation_armament": 0.98,
    "C8_encounter_confrontation": 1.0,
    "C9_slaying_decisive_action": 1.0,
    "C10_return_celebration": 0.4,
    "C11_coinage_count": 0.6,
    "C12_coinage_spread": 0.76,
    "C13_creature_naming": 0.98,
    "C14_onomatopoeia": 0.9,
    "C15_alliteration_consonance": 0.98,
    "C16_arc_order": 0.9,
    "C17_no_verbatim_lines": 1.0,
    "C18_canonical_budget": 1.0,
    "C19_syllable_tightness": 0.9,
    "C20_rhyme_variety": 0.98,
    "C21_lexical_repetition_guard": 0.98,
    "C22_coinage_variety": 0.94,
    "C23_topic_adherence": 1.0,
    "C24_subtext": 1.0,
    "label_high": 0.78,
    "label_medium": 0.22,
    "label_low": 0.0,
    "label_very_low": 0.0
  },
  "total_score": 4367,
  "spec": "mistral-medium-3.1",
  "provider": "openrouter",
  "model": "mistralai/mistral-medium-3.1",
  "num_samples": 50
}