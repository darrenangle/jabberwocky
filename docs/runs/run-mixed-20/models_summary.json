[
  {
    "spec": "gpt-4.1-mini",
    "provider": "openai",
    "model": "gpt-4.1-mini",
    "summary": {
      "overall_reward": 0.7888888888888889,
      "label_counts": {
        "very_low": 0,
        "low": 2,
        "medium": 2,
        "high": 6
      },
      "metrics_mean": {
        "composite_score": 0.7888888888888889,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.8,
        "C3_ballad_meter_echo": 0.8,
        "C4_ballad_rhyme": 0.7,
        "C5_ring_composition": 0.5,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 0.7,
        "C9_slaying_decisive_action": 0.6,
        "C10_return_celebration": 0.4,
        "C11_coinage_count": 0.9,
        "C12_coinage_spread": 0.7,
        "C13_creature_naming": 0.8,
        "C14_onomatopoeia": 0.7,
        "C15_alliteration_consonance": 0.9,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 0.9,
        "C18_canonical_budget": 0.8,
        "label_high": 0.6,
        "label_medium": 0.2,
        "label_low": 0.2,
        "label_very_low": 0.0
      }
    },
    "path": "gpt-4.1-mini/"
  },
  {
    "spec": "gpt-4.1-nano",
    "provider": "openai",
    "model": "gpt-4.1-nano",
    "summary": {
      "overall_reward": 0.4611111111111111,
      "label_counts": {
        "very_low": 0,
        "low": 8,
        "medium": 2,
        "high": 0
      },
      "metrics_mean": {
        "composite_score": 0.4611111111111111,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.4,
        "C3_ballad_meter_echo": 0.2,
        "C4_ballad_rhyme": 0.0,
        "C5_ring_composition": 0.0,
        "C6_warning_admonition": 0.4,
        "C7_preparation_armament": 0.2,
        "C8_encounter_confrontation": 0.0,
        "C9_slaying_decisive_action": 0.0,
        "C10_return_celebration": 0.0,
        "C11_coinage_count": 1.0,
        "C12_coinage_spread": 0.6,
        "C13_creature_naming": 0.5,
        "C14_onomatopoeia": 0.5,
        "C15_alliteration_consonance": 0.8,
        "C16_tone_alignment": 0.9,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 0.8,
        "label_high": 0.0,
        "label_medium": 0.2,
        "label_low": 0.8,
        "label_very_low": 0.0
      }
    },
    "path": "gpt-4.1-nano/"
  },
  {
    "spec": "gemini-2.5-flash",
    "provider": "openrouter",
    "model": "google/gemini-2.5-flash",
    "summary": {
      "overall_reward": 0.8055555555555556,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 4,
        "high": 6
      },
      "metrics_mean": {
        "composite_score": 0.8055555555555556,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.9,
        "C3_ballad_meter_echo": 0.9,
        "C4_ballad_rhyme": 0.8,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.9,
        "C10_return_celebration": 0.9,
        "C11_coinage_count": 0.3,
        "C12_coinage_spread": 0.2,
        "C13_creature_naming": 0.8,
        "C14_onomatopoeia": 0.9,
        "C15_alliteration_consonance": 0.9,
        "C16_tone_alignment": 0.9,
        "C17_no_verbatim_lines": 0.3,
        "C18_canonical_budget": 0.8,
        "label_high": 0.6,
        "label_medium": 0.4,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "gemini-2.5-flash/"
  },
  {
    "spec": "gemini-2.5-flash-lite",
    "provider": "openrouter",
    "model": "google/gemini-2.5-flash-lite",
    "summary": {
      "overall_reward": 0.6944444444444444,
      "label_counts": {
        "very_low": 0,
        "low": 2,
        "medium": 5,
        "high": 3
      },
      "metrics_mean": {
        "composite_score": 0.6944444444444444,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.8,
        "C3_ballad_meter_echo": 0.9,
        "C4_ballad_rhyme": 0.7,
        "C5_ring_composition": 0.9,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 0.8,
        "C9_slaying_decisive_action": 0.7,
        "C10_return_celebration": 0.8,
        "C11_coinage_count": 0.1,
        "C12_coinage_spread": 0.1,
        "C13_creature_naming": 0.5,
        "C14_onomatopoeia": 0.5,
        "C15_alliteration_consonance": 0.6,
        "C16_tone_alignment": 0.7,
        "C17_no_verbatim_lines": 0.5,
        "C18_canonical_budget": 0.9,
        "label_high": 0.3,
        "label_medium": 0.5,
        "label_low": 0.2,
        "label_very_low": 0.0
      }
    },
    "path": "gemini-2.5-flash-lite/"
  },
  {
    "spec": "gpt-4.1",
    "provider": "openai",
    "model": "gpt-4.1",
    "summary": {
      "overall_reward": 0.9277777777777778,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 1,
        "high": 9
      },
      "metrics_mean": {
        "composite_score": 0.9277777777777778,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.9,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.6,
        "C10_return_celebration": 0.6,
        "C11_coinage_count": 1.0,
        "C12_coinage_spread": 1.0,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.7,
        "C15_alliteration_consonance": 1.0,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 0.9,
        "label_high": 0.9,
        "label_medium": 0.1,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "gpt-4.1/"
  },
  {
    "spec": "claude-3-opus",
    "provider": "openrouter",
    "model": "anthropic/claude-3-opus",
    "summary": {
      "overall_reward": 0.8,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 6,
        "high": 4
      },
      "metrics_mean": {
        "composite_score": 0.8,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 1.0,
        "C10_return_celebration": 1.0,
        "C11_coinage_count": 0.2,
        "C12_coinage_spread": 0.2,
        "C13_creature_naming": 0.6,
        "C14_onomatopoeia": 0.9,
        "C15_alliteration_consonance": 0.8,
        "C16_tone_alignment": 0.8,
        "C17_no_verbatim_lines": 0.0,
        "C18_canonical_budget": 0.9,
        "label_high": 0.4,
        "label_medium": 0.6,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "claude-3-opus/"
  },
  {
    "spec": "claude-sonnet-4",
    "provider": "openrouter",
    "model": "anthropic/claude-sonnet-4",
    "summary": {
      "overall_reward": 0.8222222222222222,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 4,
        "high": 6
      },
      "metrics_mean": {
        "composite_score": 0.8222222222222222,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.9,
        "C10_return_celebration": 1.0,
        "C11_coinage_count": 0.2,
        "C12_coinage_spread": 0.4,
        "C13_creature_naming": 0.8,
        "C14_onomatopoeia": 0.9,
        "C15_alliteration_consonance": 0.8,
        "C16_tone_alignment": 0.9,
        "C17_no_verbatim_lines": 0.0,
        "C18_canonical_budget": 0.9,
        "label_high": 0.6,
        "label_medium": 0.4,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "claude-sonnet-4/"
  },
  {
    "spec": "claude-3.7-sonnet",
    "provider": "openrouter",
    "model": "anthropic/claude-3.7-sonnet",
    "summary": {
      "overall_reward": 0.9,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 1,
        "high": 9
      },
      "metrics_mean": {
        "composite_score": 0.9,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.8,
        "C10_return_celebration": 0.9,
        "C11_coinage_count": 0.5,
        "C12_coinage_spread": 0.8,
        "C13_creature_naming": 0.9,
        "C14_onomatopoeia": 0.9,
        "C15_alliteration_consonance": 1.0,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 0.6,
        "C18_canonical_budget": 0.8,
        "label_high": 0.9,
        "label_medium": 0.1,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "claude-3.7-sonnet/"
  },
  {
    "spec": "gpt-4o",
    "provider": "openrouter",
    "model": "openai/gpt-4o",
    "summary": {
      "overall_reward": 0.9388888888888889,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 1,
        "high": 9
      },
      "metrics_mean": {
        "composite_score": 0.9388888888888889,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.8,
        "C10_return_celebration": 0.9,
        "C11_coinage_count": 1.0,
        "C12_coinage_spread": 1.0,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.5,
        "C15_alliteration_consonance": 1.0,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 0.8,
        "C18_canonical_budget": 0.9,
        "label_high": 0.9,
        "label_medium": 0.1,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "gpt-4o/"
  },
  {
    "spec": "claude-opus-4.1",
    "provider": "openrouter",
    "model": "anthropic/claude-opus-4.1",
    "summary": {
      "overall_reward": 0.8611111111111112,
      "label_counts": {
        "very_low": 0,
        "low": 1,
        "medium": 1,
        "high": 8
      },
      "metrics_mean": {
        "composite_score": 0.8611111111111112,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 0.9,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.9,
        "C8_encounter_confrontation": 0.9,
        "C9_slaying_decisive_action": 0.9,
        "C10_return_celebration": 1.0,
        "C11_coinage_count": 0.6,
        "C12_coinage_spread": 0.6,
        "C13_creature_naming": 0.8,
        "C14_onomatopoeia": 0.9,
        "C15_alliteration_consonance": 1.0,
        "C16_tone_alignment": 0.9,
        "C17_no_verbatim_lines": 0.5,
        "C18_canonical_budget": 0.6,
        "label_high": 0.8,
        "label_medium": 0.1,
        "label_low": 0.1,
        "label_very_low": 0.0
      }
    },
    "path": "claude-opus-4.1/"
  },
  {
    "spec": "claude-opus-4",
    "provider": "openrouter",
    "model": "anthropic/claude-opus-4",
    "summary": {
      "overall_reward": 0.85,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 2,
        "high": 8
      },
      "metrics_mean": {
        "composite_score": 0.85,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.9,
        "C8_encounter_confrontation": 0.9,
        "C9_slaying_decisive_action": 0.8,
        "C10_return_celebration": 1.0,
        "C11_coinage_count": 0.3,
        "C12_coinage_spread": 0.6,
        "C13_creature_naming": 0.9,
        "C14_onomatopoeia": 0.8,
        "C15_alliteration_consonance": 0.8,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 0.4,
        "C18_canonical_budget": 0.9,
        "label_high": 0.8,
        "label_medium": 0.2,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "claude-opus-4/"
  },
  {
    "spec": "gpt-5-mini",
    "provider": "openai",
    "model": "gpt-5-mini",
    "summary": {
      "overall_reward": 0.8222222222222222,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 5,
        "high": 5
      },
      "metrics_mean": {
        "composite_score": 0.8222222222222222,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.9,
        "C3_ballad_meter_echo": 0.9,
        "C4_ballad_rhyme": 0.9,
        "C5_ring_composition": 0.2,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.9,
        "C8_encounter_confrontation": 0.8,
        "C9_slaying_decisive_action": 0.7,
        "C10_return_celebration": 0.5,
        "C11_coinage_count": 1.0,
        "C12_coinage_spread": 0.9,
        "C13_creature_naming": 0.6,
        "C14_onomatopoeia": 0.6,
        "C15_alliteration_consonance": 0.9,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 1.0,
        "label_high": 0.5,
        "label_medium": 0.5,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "gpt-5-mini/"
  },
  {
    "spec": "deepseek-chat-v3-0324",
    "provider": "openrouter",
    "model": "deepseek/deepseek-chat-v3-0324",
    "summary": {
      "overall_reward": 0.6777777777777778,
      "label_counts": {
        "very_low": 0,
        "low": 2,
        "medium": 6,
        "high": 2
      },
      "metrics_mean": {
        "composite_score": 0.6777777777777778,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 0.5,
        "C5_ring_composition": 0.5,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.7,
        "C8_encounter_confrontation": 0.5,
        "C9_slaying_decisive_action": 0.2,
        "C10_return_celebration": 0.3,
        "C11_coinage_count": 0.5,
        "C12_coinage_spread": 0.5,
        "C13_creature_naming": 0.3,
        "C14_onomatopoeia": 0.8,
        "C15_alliteration_consonance": 0.8,
        "C16_tone_alignment": 0.7,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 0.9,
        "label_high": 0.2,
        "label_medium": 0.6,
        "label_low": 0.2,
        "label_very_low": 0.0
      }
    },
    "path": "deepseek-chat-v3-0324/"
  },
  {
    "spec": "gpt-5-nano",
    "provider": "openai",
    "model": "gpt-5-nano",
    "summary": {
      "overall_reward": 0.4111111111111111,
      "label_counts": {
        "very_low": 1,
        "low": 6,
        "medium": 3,
        "high": 0
      },
      "metrics_mean": {
        "composite_score": 0.4111111111111111,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.2,
        "C3_ballad_meter_echo": 0.3,
        "C4_ballad_rhyme": 0.0,
        "C5_ring_composition": 0.1,
        "C6_warning_admonition": 0.6,
        "C7_preparation_armament": 0.2,
        "C8_encounter_confrontation": 0.1,
        "C9_slaying_decisive_action": 0.1,
        "C10_return_celebration": 0.1,
        "C11_coinage_count": 0.6,
        "C12_coinage_spread": 0.3,
        "C13_creature_naming": 0.5,
        "C14_onomatopoeia": 0.5,
        "C15_alliteration_consonance": 0.5,
        "C16_tone_alignment": 0.6,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 0.7,
        "label_high": 0.0,
        "label_medium": 0.3,
        "label_low": 0.6,
        "label_very_low": 0.1
      }
    },
    "path": "gpt-5-nano/"
  },
  {
    "spec": "deepseek-chat-v3.1",
    "provider": "openrouter",
    "model": "deepseek/deepseek-chat-v3.1",
    "summary": {
      "overall_reward": 0.85,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 4,
        "high": 6
      },
      "metrics_mean": {
        "composite_score": 0.85,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.8,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 0.9,
        "C5_ring_composition": 0.8,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.9,
        "C10_return_celebration": 0.8,
        "C11_coinage_count": 0.6,
        "C12_coinage_spread": 0.7,
        "C13_creature_naming": 0.8,
        "C14_onomatopoeia": 1.0,
        "C15_alliteration_consonance": 0.8,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 0.7,
        "C18_canonical_budget": 0.5,
        "label_high": 0.6,
        "label_medium": 0.4,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "deepseek-chat-v3.1/"
  },
  {
    "spec": "hermes-4-405b",
    "provider": "openrouter",
    "model": "nousresearch/hermes-4-405b",
    "summary": {
      "overall_reward": 0.4666666666666667,
      "label_counts": {
        "very_low": 2,
        "low": 4,
        "medium": 3,
        "high": 1
      },
      "metrics_mean": {
        "composite_score": 0.4666666666666667,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.3,
        "C3_ballad_meter_echo": 0.4,
        "C4_ballad_rhyme": 0.3,
        "C5_ring_composition": 0.3,
        "C6_warning_admonition": 0.8,
        "C7_preparation_armament": 0.7,
        "C8_encounter_confrontation": 0.6,
        "C9_slaying_decisive_action": 0.5,
        "C10_return_celebration": 0.6,
        "C11_coinage_count": 0.1,
        "C12_coinage_spread": 0.1,
        "C13_creature_naming": 0.2,
        "C14_onomatopoeia": 0.4,
        "C15_alliteration_consonance": 0.3,
        "C16_tone_alignment": 0.2,
        "C17_no_verbatim_lines": 0.6,
        "C18_canonical_budget": 1.0,
        "label_high": 0.1,
        "label_medium": 0.3,
        "label_low": 0.4,
        "label_very_low": 0.2
      }
    },
    "path": "hermes-4-405b/"
  },
  {
    "spec": "gpt-oss-120b",
    "provider": "openrouter",
    "model": "openai/gpt-oss-120b",
    "summary": {
      "overall_reward": 0.6944444444444444,
      "label_counts": {
        "very_low": 0,
        "low": 1,
        "medium": 7,
        "high": 2
      },
      "metrics_mean": {
        "composite_score": 0.6944444444444444,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.9,
        "C3_ballad_meter_echo": 0.9,
        "C4_ballad_rhyme": 0.4,
        "C5_ring_composition": 0.0,
        "C6_warning_admonition": 0.9,
        "C7_preparation_armament": 0.5,
        "C8_encounter_confrontation": 0.4,
        "C9_slaying_decisive_action": 0.4,
        "C10_return_celebration": 0.0,
        "C11_coinage_count": 1.0,
        "C12_coinage_spread": 0.9,
        "C13_creature_naming": 0.9,
        "C14_onomatopoeia": 0.6,
        "C15_alliteration_consonance": 0.9,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 0.8,
        "label_high": 0.2,
        "label_medium": 0.7,
        "label_low": 0.1,
        "label_very_low": 0.0
      }
    },
    "path": "gpt-oss-120b/"
  },
  {
    "spec": "kimi-k2",
    "provider": "openrouter",
    "model": "moonshotai/kimi-k2",
    "summary": {
      "overall_reward": 0.8833333333333333,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 1,
        "high": 9
      },
      "metrics_mean": {
        "composite_score": 0.8833333333333333,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.9,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 0.9,
        "C5_ring_composition": 0.7,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.7,
        "C10_return_celebration": 0.8,
        "C11_coinage_count": 0.9,
        "C12_coinage_spread": 0.8,
        "C13_creature_naming": 0.9,
        "C14_onomatopoeia": 0.8,
        "C15_alliteration_consonance": 1.0,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 0.8,
        "C18_canonical_budget": 0.7,
        "label_high": 0.9,
        "label_medium": 0.1,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "kimi-k2/"
  },
  {
    "spec": "llama-4-maverick",
    "provider": "openrouter",
    "model": "meta-llama/llama-4-maverick",
    "summary": {
      "overall_reward": 0.34444444444444444,
      "label_counts": {
        "very_low": 2,
        "low": 7,
        "medium": 1,
        "high": 0
      },
      "metrics_mean": {
        "composite_score": 0.34444444444444444,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.5,
        "C3_ballad_meter_echo": 0.4,
        "C4_ballad_rhyme": 0.0,
        "C5_ring_composition": 0.0,
        "C6_warning_admonition": 0.8,
        "C7_preparation_armament": 0.1,
        "C8_encounter_confrontation": 0.0,
        "C9_slaying_decisive_action": 0.0,
        "C10_return_celebration": 0.1,
        "C11_coinage_count": 0.3,
        "C12_coinage_spread": 0.2,
        "C13_creature_naming": 0.3,
        "C14_onomatopoeia": 0.0,
        "C15_alliteration_consonance": 0.3,
        "C16_tone_alignment": 0.4,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 0.8,
        "label_high": 0.0,
        "label_medium": 0.1,
        "label_low": 0.7,
        "label_very_low": 0.2
      }
    },
    "path": "llama-4-maverick/"
  },
  {
    "spec": "gemini-2.5-pro",
    "provider": "openrouter",
    "model": "google/gemini-2.5-pro",
    "summary": {
      "overall_reward": 0.9055555555555556,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 1,
        "high": 9
      },
      "metrics_mean": {
        "composite_score": 0.9055555555555556,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 0.9,
        "C5_ring_composition": 0.9,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.9,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 1.0,
        "C10_return_celebration": 0.7,
        "C11_coinage_count": 0.9,
        "C12_coinage_spread": 0.9,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.9,
        "C15_alliteration_consonance": 1.0,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 0.8,
        "C18_canonical_budget": 0.4,
        "label_high": 0.9,
        "label_medium": 0.1,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "gemini-2.5-pro/"
  },
  {
    "spec": "llama-4-scout",
    "provider": "openrouter",
    "model": "meta-llama/llama-4-scout",
    "summary": {
      "overall_reward": 0.37777777777777777,
      "label_counts": {
        "very_low": 1,
        "low": 7,
        "medium": 2,
        "high": 0
      },
      "metrics_mean": {
        "composite_score": 0.37777777777777777,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.5,
        "C3_ballad_meter_echo": 0.4,
        "C4_ballad_rhyme": 0.2,
        "C5_ring_composition": 0.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.2,
        "C8_encounter_confrontation": 0.0,
        "C9_slaying_decisive_action": 0.1,
        "C10_return_celebration": 0.2,
        "C11_coinage_count": 0.4,
        "C12_coinage_spread": 0.2,
        "C13_creature_naming": 0.3,
        "C14_onomatopoeia": 0.1,
        "C15_alliteration_consonance": 0.2,
        "C16_tone_alignment": 0.4,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 0.6,
        "label_high": 0.0,
        "label_medium": 0.2,
        "label_low": 0.7,
        "label_very_low": 0.1
      }
    },
    "path": "llama-4-scout/"
  },
  {
    "spec": "llama-3.3-70b-instruct",
    "provider": "openrouter",
    "model": "meta-llama/llama-3.3-70b-instruct",
    "summary": {
      "overall_reward": 0.29444444444444445,
      "label_counts": {
        "very_low": 6,
        "low": 3,
        "medium": 1,
        "high": 0
      },
      "metrics_mean": {
        "composite_score": 0.29444444444444445,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.3,
        "C3_ballad_meter_echo": 0.2,
        "C4_ballad_rhyme": 0.1,
        "C5_ring_composition": 0.0,
        "C6_warning_admonition": 0.5,
        "C7_preparation_armament": 0.2,
        "C8_encounter_confrontation": 0.0,
        "C9_slaying_decisive_action": 0.0,
        "C10_return_celebration": 0.0,
        "C11_coinage_count": 0.3,
        "C12_coinage_spread": 0.4,
        "C13_creature_naming": 0.2,
        "C14_onomatopoeia": 0.0,
        "C15_alliteration_consonance": 0.3,
        "C16_tone_alignment": 0.2,
        "C17_no_verbatim_lines": 0.9,
        "C18_canonical_budget": 0.7,
        "label_high": 0.0,
        "label_medium": 0.1,
        "label_low": 0.3,
        "label_very_low": 0.6
      }
    },
    "path": "llama-3.3-70b-instruct/"
  },
  {
    "spec": "glm-4.5",
    "provider": "openrouter",
    "model": "z-ai/glm-4.5",
    "summary": {
      "overall_reward": 0.8277777777777777,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 4,
        "high": 6
      },
      "metrics_mean": {
        "composite_score": 0.8277777777777777,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 0.9,
        "C5_ring_composition": 1.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.9,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.9,
        "C10_return_celebration": 1.0,
        "C11_coinage_count": 0.5,
        "C12_coinage_spread": 0.5,
        "C13_creature_naming": 0.9,
        "C14_onomatopoeia": 0.9,
        "C15_alliteration_consonance": 0.6,
        "C16_tone_alignment": 0.9,
        "C17_no_verbatim_lines": 0.3,
        "C18_canonical_budget": 0.6,
        "label_high": 0.6,
        "label_medium": 0.4,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "glm-4.5/"
  },
  {
    "spec": "gpt-5",
    "provider": "openai",
    "model": "gpt-5",
    "summary": {
      "overall_reward": 0.9555555555555556,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 1,
        "high": 9
      },
      "metrics_mean": {
        "composite_score": 0.9555555555555556,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 0.9,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 1.0,
        "C8_encounter_confrontation": 0.9,
        "C9_slaying_decisive_action": 0.8,
        "C10_return_celebration": 0.8,
        "C11_coinage_count": 1.0,
        "C12_coinage_spread": 1.0,
        "C13_creature_naming": 0.8,
        "C14_onomatopoeia": 1.0,
        "C15_alliteration_consonance": 1.0,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 1.0,
        "label_high": 0.9,
        "label_medium": 0.1,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "gpt-5/"
  },
  {
    "spec": "llama-3.1-405b-instruct",
    "provider": "openrouter",
    "model": "meta-llama/llama-3.1-405b-instruct",
    "summary": {
      "overall_reward": 0.37222222222222223,
      "label_counts": {
        "very_low": 3,
        "low": 6,
        "medium": 1,
        "high": 0
      },
      "metrics_mean": {
        "composite_score": 0.37222222222222223,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.4,
        "C3_ballad_meter_echo": 0.3,
        "C4_ballad_rhyme": 0.0,
        "C5_ring_composition": 0.0,
        "C6_warning_admonition": 0.9,
        "C7_preparation_armament": 0.4,
        "C8_encounter_confrontation": 0.1,
        "C9_slaying_decisive_action": 0.0,
        "C10_return_celebration": 0.1,
        "C11_coinage_count": 0.7,
        "C12_coinage_spread": 0.2,
        "C13_creature_naming": 0.4,
        "C14_onomatopoeia": 0.0,
        "C15_alliteration_consonance": 0.3,
        "C16_tone_alignment": 0.5,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 0.4,
        "label_high": 0.0,
        "label_medium": 0.1,
        "label_low": 0.6,
        "label_very_low": 0.3
      }
    },
    "path": "llama-3.1-405b-instruct/"
  },
  {
    "spec": "llama-3.1-nemotron-ultra-253b-v1",
    "provider": "openrouter",
    "model": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
    "summary": {
      "overall_reward": 0.6388888888888888,
      "label_counts": {
        "very_low": 1,
        "low": 2,
        "medium": 4,
        "high": 3
      },
      "metrics_mean": {
        "composite_score": 0.6388888888888888,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.4,
        "C3_ballad_meter_echo": 0.5,
        "C4_ballad_rhyme": 0.5,
        "C5_ring_composition": 0.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.9,
        "C8_encounter_confrontation": 0.8,
        "C9_slaying_decisive_action": 0.2,
        "C10_return_celebration": 0.3,
        "C11_coinage_count": 0.9,
        "C12_coinage_spread": 0.4,
        "C13_creature_naming": 0.7,
        "C14_onomatopoeia": 0.4,
        "C15_alliteration_consonance": 0.8,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 0.9,
        "C18_canonical_budget": 0.8,
        "label_high": 0.3,
        "label_medium": 0.4,
        "label_low": 0.2,
        "label_very_low": 0.1
      }
    },
    "path": "llama-3.1-nemotron-ultra-253b-v1/"
  },
  {
    "spec": "sonnet-3.5",
    "provider": "openrouter",
    "model": "anthropic/claude-3.5-sonnet",
    "summary": {
      "overall_reward": 0.8722222222222222,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 4,
        "high": 6
      },
      "metrics_mean": {
        "composite_score": 0.8722222222222222,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 0.9,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.9,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 0.9,
        "C10_return_celebration": 0.8,
        "C11_coinage_count": 0.6,
        "C12_coinage_spread": 0.6,
        "C13_creature_naming": 0.8,
        "C14_onomatopoeia": 0.7,
        "C15_alliteration_consonance": 0.9,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 0.6,
        "label_high": 0.6,
        "label_medium": 0.4,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "sonnet-3.5/"
  },
  {
    "spec": "glm-4.5-air",
    "provider": "openrouter",
    "model": "z-ai/glm-4.5-air",
    "summary": {
      "overall_reward": 0.5833333333333334,
      "label_counts": {
        "very_low": 0,
        "low": 4,
        "medium": 4,
        "high": 2
      },
      "metrics_mean": {
        "composite_score": 0.5833333333333334,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.5,
        "C3_ballad_meter_echo": 0.7,
        "C4_ballad_rhyme": 0.3,
        "C5_ring_composition": 0.1,
        "C6_warning_admonition": 0.9,
        "C7_preparation_armament": 0.8,
        "C8_encounter_confrontation": 0.6,
        "C9_slaying_decisive_action": 0.5,
        "C10_return_celebration": 0.7,
        "C11_coinage_count": 0.4,
        "C12_coinage_spread": 0.4,
        "C13_creature_naming": 0.7,
        "C14_onomatopoeia": 0.5,
        "C15_alliteration_consonance": 0.6,
        "C16_tone_alignment": 0.6,
        "C17_no_verbatim_lines": 0.5,
        "C18_canonical_budget": 0.7,
        "label_high": 0.2,
        "label_medium": 0.4,
        "label_low": 0.4,
        "label_very_low": 0.0
      }
    },
    "path": "glm-4.5-air/"
  },
  {
    "spec": "qwen3-30b-a3b",
    "provider": "openrouter",
    "model": "qwen/qwen3-30b-a3b",
    "summary": {
      "overall_reward": 0.4444444444444444,
      "label_counts": {
        "very_low": 0,
        "low": 8,
        "medium": 2,
        "high": 0
      },
      "metrics_mean": {
        "composite_score": 0.4444444444444444,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.3,
        "C3_ballad_meter_echo": 0.2,
        "C4_ballad_rhyme": 0.0,
        "C5_ring_composition": 0.0,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.1,
        "C8_encounter_confrontation": 0.1,
        "C9_slaying_decisive_action": 0.1,
        "C10_return_celebration": 0.0,
        "C11_coinage_count": 0.9,
        "C12_coinage_spread": 0.4,
        "C13_creature_naming": 0.4,
        "C14_onomatopoeia": 0.7,
        "C15_alliteration_consonance": 0.5,
        "C16_tone_alignment": 0.8,
        "C17_no_verbatim_lines": 0.9,
        "C18_canonical_budget": 0.6,
        "label_high": 0.0,
        "label_medium": 0.2,
        "label_low": 0.8,
        "label_very_low": 0.0
      }
    },
    "path": "qwen3-30b-a3b/"
  },
  {
    "spec": "grok-code-fast-1",
    "provider": "openrouter",
    "model": "x-ai/grok-code-fast-1",
    "summary": {
      "overall_reward": 0.8722222222222222,
      "label_counts": {
        "very_low": 0,
        "low": 0,
        "medium": 2,
        "high": 8
      },
      "metrics_mean": {
        "composite_score": 0.8722222222222222,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 0.9,
        "C3_ballad_meter_echo": 1.0,
        "C4_ballad_rhyme": 1.0,
        "C5_ring_composition": 0.8,
        "C6_warning_admonition": 1.0,
        "C7_preparation_armament": 0.9,
        "C8_encounter_confrontation": 1.0,
        "C9_slaying_decisive_action": 1.0,
        "C10_return_celebration": 1.0,
        "C11_coinage_count": 0.8,
        "C12_coinage_spread": 0.7,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.8,
        "C15_alliteration_consonance": 0.9,
        "C16_tone_alignment": 0.9,
        "C17_no_verbatim_lines": 0.4,
        "C18_canonical_budget": 0.6,
        "label_high": 0.8,
        "label_medium": 0.2,
        "label_low": 0.0,
        "label_very_low": 0.0
      }
    },
    "path": "grok-code-fast-1/"
  },
  {
    "spec": "deepseek-r1-0528",
    "provider": "openrouter",
    "model": "deepseek/deepseek-r1-0528",
    "summary": {
      "overall_reward": 0.8666666666666667,
      "label_counts": {
        "very_low": 0,
        "low": 1,
        "medium": 1,
        "high": 8
      },
      "metrics_mean": {
        "composite_score": 0.8666666666666667,
        "C1_title_present": 1.0,
        "C2_quatrain_shape": 1.0,
        "C3_ballad_meter_echo": 0.9,
        "C4_ballad_rhyme": 0.9,
        "C5_ring_composition": 0.4,
        "C6_warning_admonition": 0.9,
        "C7_preparation_armament": 0.8,
        "C8_encounter_confrontation": 0.9,
        "C9_slaying_decisive_action": 0.7,
        "C10_return_celebration": 0.7,
        "C11_coinage_count": 0.9,
        "C12_coinage_spread": 0.9,
        "C13_creature_naming": 1.0,
        "C14_onomatopoeia": 0.9,
        "C15_alliteration_consonance": 0.9,
        "C16_tone_alignment": 1.0,
        "C17_no_verbatim_lines": 1.0,
        "C18_canonical_budget": 0.8,
        "label_high": 0.8,
        "label_medium": 0.1,
        "label_low": 0.1,
        "label_very_low": 0.0
      }
    },
    "path": "deepseek-r1-0528/"
  }
]